---
title: "B1 Topic Modeling"
author: "Nathan Moore"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
## Global knitr options
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache = FALSE)
knitr::opts_chunk$set(autodep = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

```

```{r, warning = FALSE, message = FALSE}
## Increase Memory Limit
invisible(utils::memory.limit(64000))
options(java.parameters = "-Xmx64000m")

## Data Frame Packages
library(dplyr)
library(stringr)
library(readr)
library(readxl)

## Data Visualization Packages
library(ggplot2)
library(Rtsne)

## Text Mining Pacakges
library(data.table)
library(Matrix)
library(text2vec)
library(tm)
library(SnowballC)
library(rARPACK)
```


## Load Data

First we load the text and meta data of the active grants.  We pull four sources of text:
\begin{itemize}
\item T - Title
\item A - Abstract
\item N - Narrative (also known as Public Health Relevance)
\item S - Specific Aims
\end{itemize}
```{r, message = FALSE, cache = TRUE}
nih1 = read_csv("Bioinformatics Meta Data 2009+.csv", guess_max = 1000000)
nih1 = (
  nih1 %>% mutate(PAC = substr(PCC, 1, 4),
                  PO = substr(PCC, 5, 6))
)

nih2 = read_csv("Bioinformatics Text Data 2009+.csv", guess_max = 1000000)

nih = inner_join(nih1, nih2)
nih = data.frame(nih)
nih = filter(nih, (Funded == "Y" | (Competing == "Y" & !is.na(RecomCode))),
             !is.na(T), 
             !is.na(A))

rm(nih1)
rm(nih2)

meta = select(nih, AID:T)

str(nih)
```

\newpage

## IC 

Which ICs do we have?
```{r}
table(nih$IC)
```

We can get rid of the non GM apps if we chose to do so.
```{r}
#nih = filter(nih, IC == "GM")

table(nih$IC)
```

## Activity

```{r}
table(nih$Activity)
```

Let's restrict to R01 equivalents

```{r}
r01 = c("DP1", "DP2", "DP5", "R01", "R35", "R37", "R56", "RF1", "RL1", "U01")

nih = filter(nih, Activity %in% r01)

table(nih$Activity)
```

## PAC

Let's see which Program Area Codes (PACs) there are.
```{r}
table(nih$PAC)
```

We can get rid of unwanted PACs, inlcuding B170 which is going away.
```{r}
#nih = filter(nih, PAC %in% p$PAC, PAC != "B170")
#str(nih)
table(nih$PAC)
```

## PO

Let's see how many apps each PO has.
```{r}
table(nih$PO)
```

## Active

Let's only keep apps that are active as of 01-01-2020.
```{r}
nih = (
  nih %>% mutate(BudgetEnd = as.Date(BudgetEnd, format = "%m/%d/%Y"))
      %>% filter(Funded == "Y" & BudgetEnd >= "2020-01-01")
)

#str(nih)
#table(nih$PCC)
table(nih$PO)
```

## Text Variable

Let's create a text variable.
```{r}
text = c("T", "A", "N")

nih$Text = nih[, text[1]]
if(length(text) > 1){
  for(i in 2:length(text)){
    nih$Text = paste(nih$Text, nih[, text[i]])
  }
}

nih = select(nih, -c(T, A, N, S))
nih = mutate(nih, Text = ifelse(is.na(Text), "", Text))
nih = filter(nih, Text != "")

cat("Sections used:", text, "\n\n")

#str(nih)
```

### Clean Up Text

Let's clean up the text by making everything lowercase, removing punctuation, etc.
```{r}
# Remove weird characters
nih$Text = str_replace_all(nih$Text, "\n", " ")
nih$Text = str_replace_all(nih$Text, "\r", " ")
nih$Text = str_replace_all(nih$Text, "'", "")
nih$Text = str_replace_all(nih$Text, "-", " ")

# Replace non-alpha numeric characters with a space
nih$Text = str_replace_all(nih$Text, "[^abcdefghijklmnopqrstuvwxyzABCDEFHIJKLMNOPQRSTUVWXZ0123456789 ]", " ")

# Put everything in lowercase
nih$Text = tolower(nih$Text)

# Remove a few select words and extra speaces
nih$Text = str_replace_all(nih$Text, "abstract", " ")
nih$Text = str_replace_all(nih$Text, "project", " ")
nih$Text = str_replace_all(nih$Text, "summary", " ")
nih$Text = str_replace_all(nih$Text, "narrative", " ")
nih$Text = str_replace_all(nih$Text, "\\s+", " ")
nih$Text = str_replace_all(nih$Text, "description provided by applicant", " ")
nih$Text = str_replace_all(nih$Text, "\\s+", " ")
nih$Text = str_trim(nih$Text, side = "both")

#str(nih)
#table(nih$PO)
```

### Unique Text

Let's only keep applications with unique text.
```{r}
nih = (
  nih %>% group_by(Text)
      %>% arrange(desc(Council), desc(AID))
      %>% filter(row_number() == 1)
      %>% ungroup()
      %>% data.frame()
)

#str(nih)
#table(nih$PCC)
table(nih$PO)
```


## DTM

Let's build a Document-Term Matrix (DTM).
```{r}
setDT(nih)
setkey(nih, AID)
#AID = nih$AID
```


###  Vocabulary

Let's build a vocabulary that uses stemming.
```{r}
stem_tokenizer =function(x) {
  word_tokenizer(x) %>% lapply(SnowballC::wordStem, language="en") 
  }

it = itoken(nih$Text,
            #tokenizer = word_tokenizer, 
            tokenizer = stem_tokenizer,
            ids = nih$AID, 
            progressbar = FALSE)

stop = stopwords(kind = "SMART")
stop = str_replace_all(stop, "'", "")

vocab = create_vocabulary(it, stopwords = stop, ngram = c(1L, 2L))

cat("Number of terms in vocabulary:", dim(vocab)[1])
#vocab %>% arrange(desc(term_count)) %>% head(20)
```

Let's prune the vocabulary by only including terms that appear at least 10 times.
```{r}
vocab = prune_vocabulary(vocab,
                                term_count_min = 10)
                                #doc_count_min = 5,
                                #doc_proportion_max = 0.9,
                                #doc_proportion_min = 0.001)

cat("Number of terms in vocabulary:", dim(vocab)[1])
#vocab %>% arrange(desc(term_count)) %>% head(20)
```

### Extra Stop Words

```{r}
paul1 = read_excel("B1_Round1_2019-12-06.xlsx", sheet = "Stopwords")
paul2 = read_excel("B1_Round2_2019-12-06.xlsx", sheet = "Stopwords")
paul = rbind(paul1, paul2)
paul = paul$Stopword
print(paul)

vocab = filter(vocab, !(term %in% paul))
cat("\nNumber of terms in vocabulary:", dim(vocab)[1])
```


### Build DTM

Now let's build the DTM for the training data.
```{r}
vectorizer = vocab_vectorizer(vocab)
dtm = create_dtm(it, vectorizer)

#identical(rownames(dtm), as.character(nih$AID))

cat("DTM dimensions:", dim(dtm))
```

## Topic Modeling

Here we use the most popular topic modeling algorithm, Latent Dirichlet Allocation (LDA).  LDA assigns a probability to each word of belonging to each topic, and then assigns a percentage of each topic to each document.  For example, if we had 2 topics, LDA would assign two percentages (which add up to 100%) to each document.  Here we plot the 20 most indicative words of each topic, and the distribution of the most likely topics of the documents.

### Lowest Perplexity

UNCOMMENT THIS CODE TO FIND THE OPTIMAL PARAMETERS AGAIN
```{r}
# as = c(0.05, 10^(-5:5))
# bs = c(0.05, 10^(-5:5))
# topics = 3:8
# 
# pp = NULL
# 
# for(topic in topics){
#   a1 = 50/topic # Default Values
#   b1 = 1/topic  # Default Values
#   lda_model = LDA$new(doc_topic_prior = a1, 
#                       topic_word_prior = b1,
#                       n_topics = topic)
#   
#   set.seed(123)
#   doc_topic_distr = 
#        lda_model$fit_transform(x = dtm, 
#                                n_iter = 1000, 
#                                convergence_tol = 0.0001, 
#                                n_check_convergence = 25, 
#                                progressbar = FALSE,
#                                verbose = FALSE)
#   
#   topic_word_distr = lda_model$topic_word_distribution
#   
#   p1 = perplexity(dtm, topic_word_distr, doc_topic_distr)
#   
#   print(paste(a1, b1, p1))
#   
#   for(a in as){
#     for(b in bs){
#       lda_model = LDA$new(doc_topic_prior = a, 
#                           topic_word_prior = b,
#                           n_topics = topic)
#       
#       set.seed(123)
#       doc_topic_distr = 
#            lda_model$fit_transform(x = dtm, 
#                                    n_iter = 1000, 
#                                    convergence_tol = 0.0001, 
#                                    n_check_convergence = 25, 
#                                    progressbar = FALSE,
#                                    verbose = FALSE)
#       
#       topic_word_distr = lda_model$topic_word_distribution
#       
#       p = perplexity(dtm, topic_word_distr, doc_topic_distr)
#       
#       print(paste(topic, a, b, p))
#       
#       if(p < p1){
#         a1 = a
#         b1 = b
#         p1 = p
#       }
#     }
#   }
#   
#   pp1 = data.frame(Topics = topic, Alpha = a1, Beta = b1, Perplexity = p1)
#   pp = rbind(pp, pp1)
# }
# 
# cat("\n\n")
# 
# pp
# write_csv(pp, "B1_Optimal_Parameters.csv")
```

Let's load the optimal parameters.
```{r}
pp = read_csv("B1_Optimal_Parameters.csv")
pp = data.frame(pp)

str(pp)
```

Now we choose the desired number of topic.
```{r, message = FALSE, warining = FALSE}
topic = 7

pp1 = filter(pp, Topics == topic)
a1 = pp1$Alpha
b1 = pp1$Beta
t1 = pp1$Topics

lda_model = LDA$new(doc_topic_prior = a1, 
                    topic_word_prior = b1,
                    n_topics = t1)

set.seed(123)
doc_topic_distr = 
     lda_model$fit_transform(x = dtm, 
                             n_iter = 1000, 
                             convergence_tol = 0.0001, 
                             n_check_convergence = 25, 
                             progressbar = FALSE,
                             verbose = FALSE)

topic_word_distr = lda_model$topic_word_distribution


#cat("\n\n")

d = as.matrix(doc_topic_distr)
d = data.frame(AID = as.integer(row.names(d)), d)
colnames(d) = str_replace_all(names(d), "X", "T")

 for(i in 1:dim(d)[1]){
    temp = names(sort(d[i, 2:dim(d)[2]], decreasing = TRUE))[1:2]
    d[i, "Topic1"] = temp[1]
    d[i, "Topic2"] = temp[2]
 }

#d$Topic = factor(d$Topic)

l = dim(d)[2]
d = d[, c(1, l-1,l, 4:l-2)]

cat("\n\n")

k = lda_model$get_top_words(n = 20, topic_number = 1:t1, lambda = 0.25)

k

#cat("\n\n")

#perplexity(dtm, topic_word_distr, doc_topic_distr)

#cat("\n")
table(d$Topic1)

k1 = data.frame(k)
colnames(k1) = paste0("Topic", 1:t1)

#str(k1)
```

## LDAvis

```{r}
lda_model$plot()
```

\newpage


## 2D Plots

Here we dimensionally reduce the feature vectors of each grant to two dimensions using the t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm and plot each grant in the reduced 2D space.

```{r, message = FALSE, warning = FALSE, fig.height = 4.1}
p = inner_join(select(nih, AID:PO), d)

n = names(p)
n1 = names(select(p, AID:Topic2))
n2 = sort(n[!(n %in% n1)])

dtm2 = as.matrix(dtm)
dtm3 = data.frame(dtm2)
dtm3$AID = as.integer(row.names(dtm2))
dtm4 = inner_join(select(p, AID, Topic1, PO), dtm3)

set.seed(123)

ts = Rtsne(as.matrix(select(dtm4, -AID, -Topic1, -PO)), check_duplicates=FALSE, pca=TRUE, perplexity=30, theta=0.5, dims=2)
dts = as.data.frame(ts$Y)
dts2 = cbind(select(dtm4, AID, Topic1, PO), dts)
dts2 = rename(dts2, PO = PO)

 (
    ggplot(dts2, aes(x = V1, y = V2, col = Topic1))
  + geom_point()
  + ggtitle("Most Likley Topic of Each Grant in Term Frequency Space")
  + theme_minimal()
  + theme(legend.position = "bottom",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4))
 )


 (
    ggplot(dts2, aes(x = V1, y = V2, col = PO))
  + geom_point()
  + ggtitle("PO of Each Grant in Term Frequency Space")
  + theme_minimal()
  + theme(legend.position = "bottom",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4))
 )



set.seed(123)

ts = Rtsne(as.matrix(select(p, n2)), check_duplicates=FALSE, pca=TRUE, perplexity=30, theta=0.5, dims=2)
dts = as.data.frame(ts$Y)
dts2 = cbind(select(p, AID, Topic1, PO), dts)
dts2 = rename(dts2, PO = PO)

 (
    ggplot(dts2, aes(x = V1, y = V2, col = Topic1)) 
  + geom_point()
  + ggtitle("Most Likely Topic of Each Grant in Topic Space")
  + theme_minimal()
  + theme(legend.position = "bottom",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4))
 )



 (
    ggplot(dts2, aes(x = V1, y = V2, col = PO)) 
  + geom_point()
  + ggtitle("PO of Each Grant in Topic Space")
  + theme_minimal()
  + theme(legend.position = "bottom",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4)) 
 )
```

\newpage

## Most Likely Topics of POs

Here we look at the breakdown of most likely topic (topic with the highest percentage) by PO.

```{r, fig.height = 4.1}
p1 = (
  p %>% group_by(PO)
    %>% mutate(N = n())
    %>% ungroup()
    %>% group_by(PO, Topic1, N)
    %>% summarize(n = n())
    %>% ungroup()
    %>% mutate(Percentage = round(100*n/N))
)

(
    ggplot(p1, aes(x = PO, y = n, fill = Topic1))
  + geom_bar(stat = "identity", width = 0.8)
  + ylab("Frequency")
  + xlab("PO")
  + ggtitle("Most Likely Topics of POs (Frequency in Portfolio)")
  #+ scale_y_continuous(labels = scales::percent)
  + theme_minimal()
  + theme(legend.position = "right",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4)) 
)

(
    ggplot(p1, aes(x = PO, y = Percentage/100, fill = Topic1))
  + geom_bar(stat = "identity", width = 0.8)
  + ylab("Percentage")
  + xlab("PO")
  + ggtitle("Most Likely Topics of POs (Percentage of Portfolio)")
  + scale_y_continuous(labels = scales::percent)
  + theme_minimal()
  + theme(legend.position = "right",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4)) 
)
```

## Distributions of Topics

Here we look at the distributions of the percentages of each topic in each grant, and the topic distributions of each PO's portfolio.  We use standard (Tukey) boxplots. In the boxplots, the black lines are the medians and the solid black dots are the means.

```{r, fig.height = 4.1}

p1 = (
  p %>% select(PO, n2)
    %>% melt(measure.vars = n2, variable.name = "Topic", value.name = "Fraction")
    %>% arrange(PO)
)

g = (
    ggplot(p1, aes(x = Topic, y = Fraction, fill = Topic))
  + geom_boxplot(width = 0.8, outlier.shape = 1)
  + stat_summary(fun.y = "mean", geom = "point", size = 0.9)
  + ylab("Percentage")
  + xlab("Topic")
  + ggtitle("Distribution of Topic Percentages")
  + scale_y_continuous(labels = scales::percent)
  + theme_minimal()
  + theme(legend.position = "none",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4)) 
)

print(g)

g1 = ggplot_build(g)
colors = unique(g1$data[[1]]["fill"])
colors$Topic = sort(unique(p1$Topic))

(
    ggplot(p1, aes(x = PO, y = Fraction, fill = Topic))
  + geom_boxplot(width = 0.8, outlier.shape = 1)
  + stat_summary(fun.y = "mean", geom = "point", position = position_dodge(width=0.8), size = 0.9)
  + ylab("Percentage")
  + xlab("PO")
  + ggtitle("Distribution of Topic Percentages by PO")
  + scale_y_continuous(labels = scales::percent)
  + theme_minimal()
  + theme(legend.position = "right",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4)) 
)
```


```{r, fig.height = 4.1}
for(topic in sort(unique(p1$Topic))){
  g = (
      ggplot(filter(p1, Topic == topic), aes(x = PO, y = Fraction))
    + geom_boxplot(width = 0.8, fill = colors[colors$Topic == topic, "fill"], outlier.shape = 1)
    + stat_summary(fun.y = "mean", geom = "point", size = 0.9)
    + ylab("Percentage")
    + xlab("PO")
    + scale_y_continuous(limits = c(0,1), labels = scales::percent)
    + ggtitle(paste("Distribution of Topic", topic, "by PO"))
    + theme_minimal()
    + theme(legend.position = "right",
                plot.title = element_text(hjust = 0.5),
                plot.subtitle = element_text(hjust = 0.5),
                #axis.text.x = element_text(color = s$Color),
                panel.grid.major.x = element_blank())
  )
  
  print(g)
  cat("\n\n")
}
```

## Output Application Topics

```{r}
p2 = (
  p %>% mutate(Project = paste0(Type, 
                                Activity,
                                IC,
                                str_pad(Serial, 6, "left", "0"),
                                "-",
                                str_pad(Year, 2, "left", "0"),
                                ifelse(!is.na(Suffix), Suffix, "")),
               T1 = round(100*T1, 2),
               T2 = round(100*T2, 2),
               T3 = round(100*T3, 2),
               T4 = round(100*T4, 2),
               T5 = round(100*T5, 2),
               T6 = round(100*T6, 2),
               T7 = round(100*T7, 2))
    %>% inner_join(select(meta, AID, T))
    %>% rename(Title = T, Topic = Topic1)
    %>% mutate(Title = paste0('=HYPERLINK(', 
                              '"https://apps.era.nih.gov/qvr/web/dd_abstract.cfm?ApplId=', 
                              AID, 
                              '&sourceCode=CURRENT&rcdc=Y"', 
                              ', "', 
                              Title, '")'))
    #%>% select(AID, Project, PO, Topic, T1:T7, Title)
)

#str(p2)

write_csv(p2, "B1 Active R01 Equivalent Grants.csv")
```

