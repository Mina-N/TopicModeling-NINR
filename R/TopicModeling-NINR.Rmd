---
title: "TopicModeling-NINR"
author: "Mina Narayanan"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
## Global knitr options
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache = FALSE)
knitr::opts_chunk$set(autodep = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

```

```{r, warning = FALSE, message = FALSE}
## Increase Memory Limit
invisible(utils::memory.limit(64000))
options(java.parameters = "-Xmx64000m")

## Data Frame Packages
library(dplyr)
library(stringr)
library(readr)
library(readxl)

## Data Visualization Packages
library(ggplot2)
library(Rtsne)

## Text Mining Pacakges
library(data.table)
library(Matrix)
library(text2vec)
library(tm)
library(SnowballC)
library(rARPACK)
```


## Load Data

First we load the data of NINR grants awarded in 2019.  We pull four sources of text:
\begin{itemize}
\item T - Title
\item A - Abstract Text
\item S - Specific Aims (SA) Text
\end{itemize}x
```{r, message = FALSE, cache = TRUE}
awardedNINR19 = read_excel("./../data/awarded-grants-NINR-2019.xlsx", guess_max = 1000000)
nrow(awardedNINR19)

table(awardedNINR19$Type)
table(awardedNINR19$Actv)
table(awardedNINR19$PCC)
table(awardedNINR19$Project)
```

Let's restrict to R01 equivalents

```{r}
r01 = c("DP1", "DP2", "DP5", "R01", "R35", "R37", "R56", "RF1", "RL1", "U01")

awardedNINR19_r01 = filter(awardedNINR19, Actv %in% r01)

table(awardedNINR19_r01$Actv)
```

## Text Variable

Let's create a text variable.
```{r}
text = c("Title", "Abstract Text (only)", "SA Text")

awardedNINR19$Text <- awardedNINR19[[text[1]]]
if(length(text) > 1){
  for(i in 2:length(text)){
    awardedNINR19$Text <- paste(awardedNINR19$Text, awardedNINR19[[text[i]]])
    print(i)
  }
}
print(substr(awardedNINR19[1, "Text"], 1000, 11000))

awardedNINR19 = select(awardedNINR19, -c("Title", "Abstract Text (only)", "SA Text"))
awardedNINR19 = mutate(awardedNINR19, Text = ifelse(is.na(Text), "", Text))
awardedNINR19 = filter(awardedNINR19, Text != "")

cat("Sections used:", text, "\n\n")
```

### Clean Up Text

Let's clean up the text by making everything lowercase, removing punctuation, etc.
```{r}
# Remove weird characters
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "\n", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "\r", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "'", "")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "-", " ")

# Replace non-alpha numeric characters with a space
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "[^abcdefghijklmnopqrstuvwxyzABCDEFHIJKLMNOPQRSTUVWXZ0123456789 ]", " ")

# Put everything in lowercase
awardedNINR19$Text = tolower(awardedNINR19$Text)

# Remove a few select words and extra spaces
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "abstract", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "project", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "proposal", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "summary", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "narrative", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "background", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "supplement", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "significance", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "overall", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "title", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "specific aims", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "goal", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "research plan", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "overview", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "\\s+", " ")
awardedNINR19$Text = str_replace_all(awardedNINR19$Text, "description provided by applicant", " ")

awardedNINR19$Text = str_trim(awardedNINR19$Text, side = "both")

```

### Unique Text

Let's only keep applications with unique text.
```{r}
awardedNINR19 = (
  awardedNINR19 %>% group_by(Text)
      %>% arrange(desc(Project))
      %>% filter(row_number() == 1)
      %>% ungroup()
      %>% data.frame()
)

nrow(awardedNINR19)

```


## DTM

Let's build a Document-Term Matrix (DTM).
```{r}
setDT(awardedNINR19)
setkey(awardedNINR19, Project)
```


###  Vocabulary

Let's build a vocabulary that uses stemming.
```{r}
stem_tokenizer =function(x) {
  word_tokenizer(x) %>% lapply(SnowballC::wordStem, language="en") 
  }

it = itoken(awardedNINR19$Text,
            #tokenizer = word_tokenizer, 
            tokenizer = stem_tokenizer,
            ids = awardedNINR19$Project, 
            progressbar = FALSE)

stop = stopwords(kind = "SMART")
stop = str_replace_all(stop, "'", "")

vocab = create_vocabulary(it, stopwords = stop, ngram = c(1L, 2L))

cat("Number of terms in vocabulary:", dim(vocab)[1])
#vocab %>% arrange(desc(term_count)) %>% head(20)
```

Let's prune the vocabulary by only including terms that appear at least 10 times.
```{r}
vocab = prune_vocabulary(vocab,
                                term_count_min = 10)
                                #doc_count_min = 5,
                                #doc_proportion_max = 0.9,
                                #doc_proportion_min = 0.001)

cat("Number of terms in vocabulary:", dim(vocab)[1])
#vocab %>% arrange(desc(term_count)) %>% head(20)
```

### Extra Stop Words

```{r}
# TODO: Create list of custom stopwords
#paul1 = read_excel("B1_Round1_2019-12-06.xlsx", sheet = "Stopwords")
#paul2 = read_excel("B1_Round2_2019-12-06.xlsx", sheet = "Stopwords")
#paul = rbind(paul1, paul2)
#paul = paul$Stopword
#print(paul)

#vocab = filter(vocab, !(term %in% paul))
#cat("\nNumber of terms in vocabulary:", dim(vocab)[1])
```


### Build DTM

Now let's build the DTM for the training data.
```{r}
vectorizer = vocab_vectorizer(vocab)
dtm = create_dtm(it, vectorizer)

#identical(rownames(dtm), as.character(nih$AID))

cat("DTM dimensions:", dim(dtm))
```

## Topic Modeling

Here we use the most popular topic modeling algorithm, Latent Dirichlet Allocation (LDA).  LDA assigns a probability to each word of belonging to each topic, and then assigns a percentage of each topic to each document.  For example, if we had 2 topics, LDA would assign two percentages (which add up to 100%) to each document.  Here we plot the 20 most indicative words of each topic, and the distribution of the most likely topics of the documents.

### Lowest Perplexity

UNCOMMENT THIS CODE TO FIND THE OPTIMAL PARAMETERS AGAIN
```{r}
 as = c(0.05, 10^(-5:5))
 bs = c(0.05, 10^(-5:5))
 topics = 3:8
 
 pp = NULL
 
 for(topic in topics){
   a1 = 50/topic # Default Values
   b1 = 1/topic  # Default Values
   lda_model = LDA$new(doc_topic_prior = a1, 
                       topic_word_prior = b1,
                       n_topics = topic)
   
   set.seed(123)
   doc_topic_distr = 
        lda_model$fit_transform(x = dtm, 
                                n_iter = 1000, 
                                convergence_tol = 0.0001, 
                                n_check_convergence = 25, 
                                progressbar = FALSE,
                                verbose = FALSE)
   
   topic_word_distr = lda_model$topic_word_distribution
  
   p1 = perplexity(dtm, topic_word_distr, doc_topic_distr)
   
   print(paste(a1, b1, p1))
   
   for(a in as){
     for(b in bs){
       lda_model = LDA$new(doc_topic_prior = a, 
                           topic_word_prior = b,
                           n_topics = topic)
       
       set.seed(123)
       doc_topic_distr = 
            lda_model$fit_transform(x = dtm, 
                                    n_iter = 1000, 
                                    convergence_tol = 0.0001, 
                                    n_check_convergence = 25, 
                                    progressbar = FALSE,
                                    verbose = FALSE)
       
       topic_word_distr = lda_model$topic_word_distribution
       
       p = perplexity(dtm, topic_word_distr, doc_topic_distr)
       # TODO: Check coherence
       
       print(paste(topic, a, b, p))
       
       if(p < p1){
         a1 = a
         b1 = b
         p1 = p
       }
     }
   }
   
   pp1 = data.frame(Topics = topic, Alpha = a1, Beta = b1, Perplexity = p1)
   pp = rbind(pp, pp1)
 }
 
 cat("\n\n")
 
 pp
 write_csv(pp, "LDA_Opt_Param_NINR.csv")
```

Let's load the optimal parameters.
```{r}
pp = read_csv("LDA_Opt_Param_NINR.csv")
pp = data.frame(pp)

str(pp)
```

Now we choose the desired number of topic.
```{r, message = FALSE, warining = FALSE}
topic = 8

pp1 = filter(pp, Topics == topic)
a1 = pp1$Alpha
b1 = pp1$Beta
t1 = pp1$Topics

lda_model = LDA$new(doc_topic_prior = a1, 
                    topic_word_prior = b1,
                    n_topics = t1)

set.seed(123)
doc_topic_distr = 
     lda_model$fit_transform(x = dtm, 
                             n_iter = 1000, 
                             convergence_tol = 0.0001, 
                             n_check_convergence = 25, 
                             progressbar = FALSE,
                             verbose = FALSE)

topic_word_distr = lda_model$topic_word_distribution


#cat("\n\n")

d = as.matrix(doc_topic_distr)
d = data.frame(Project = row.names(d), d)
colnames(d) = str_replace_all(names(d), "X", "T")

 for(i in 1:dim(d)[1]){
    temp = names(sort(d[i, 2:dim(d)[2]], decreasing = TRUE))[1:2]
    d[i, "Topic1"] = temp[1]
    d[i, "Topic2"] = temp[2]
 }

#d$Topic = factor(d$Topic)

l = dim(d)[2]
d = d[, c(1, l-1,l, 4:l-2)]

cat("\n\n")

k = lda_model$get_top_words(n = 20, topic_number = 1:t1, lambda = 0.25)

k

#cat("\n\n")

#perplexity(dtm, topic_word_distr, doc_topic_distr)

#cat("\n")
table(d$Topic1)

k1 = data.frame(k)
colnames(k1) = paste0("Topic", 1:t1)

#str(k1)
```

## LDAvis

```{r}
lda_model$plot()
```

\newpage


## 2D Plots

Here we dimensionally reduce the feature vectors of each grant to two dimensions using the t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm and plot each grant in the reduced 2D space.

```{r, message = FALSE, warning = FALSE, fig.height = 4.1}
p = inner_join(select(awardedNINR19, Project:PO.Name), d)

n = names(p)
n1 = names(select(p, Project:Topic2))
n2 = sort(n[!(n %in% n1)])

dtm2 = as.matrix(dtm)
dtm3 = data.frame(dtm2)
dtm3$Project = row.names(dtm2)
dtm4 = inner_join(select(p, Project, Topic1, PO.Name), dtm3)

set.seed(123)

ts = Rtsne(as.matrix(select(dtm4, -Project, -Topic1, -PO.Name)), check_duplicates=FALSE, pca=TRUE, perplexity=30, theta=0.5, dims=2)
dts = as.data.frame(ts$Y)
dts2 = cbind(select(dtm4, Project, Topic1, PO.Name), dts)
dts2 = rename(dts2, PO.Name = PO.Name)

 (
    ggplot(dts2, aes(x = V1, y = V2, col = Topic1))
  + geom_point()
  + ggtitle("Most Likley Topic of Each Grant in Term Frequency Space")
  + theme_minimal()
  + theme(legend.position = "bottom",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4))
 )


 (
    ggplot(dts2, aes(x = V1, y = V2, col = PO.Name))
  + geom_point()
  + ggtitle("PO of Each Grant in Term Frequency Space")
  + theme_minimal()
  + theme(legend.position = "bottom",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4))
 )



set.seed(123)

ts = Rtsne(as.matrix(select(p, n2)), check_duplicates=FALSE, pca=TRUE, perplexity=30, theta=0.5, dims=2)
dts = as.data.frame(ts$Y)
dts2 = cbind(select(p, Project, Topic1, PO.Name), dts)
dts2 = rename(dts2, PO.Name = PO.Name)

 (
    ggplot(dts2, aes(x = V1, y = V2, col = Topic1)) 
  + geom_point()
  + ggtitle("Most Likely Topic of Each Grant in Topic Space")
  + theme_minimal()
  + theme(legend.position = "bottom",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4))
 )


 (
    ggplot(dts2, aes(x = V1, y = V2, col = PO.Name)) 
  + geom_point()
  + ggtitle("PO of Each Grant in Topic Space")
  + theme_minimal()
  + theme(legend.position = "bottom",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4)) 
 )
```

\newpage

## Most Likely Topics of POs

Here we look at the breakdown of most likely topic (topic with the highest percentage) by PO.

```{r, fig.height = 4.1}
p1 = (
  p %>% group_by(PO.Name)
    %>% mutate(N = n())
    %>% ungroup()
    %>% group_by(PO.Name, Topic1, N)
    %>% summarize(n = n())
    %>% ungroup()
    %>% mutate(Percentage = round(100*n/N))
)

(
    ggplot(p1, aes(x = PO.Name, y = n, fill = Topic1))
  + geom_bar(stat = "identity", width = 0.8)
  + ylab("Frequency")
  + xlab("PO")
  + ggtitle("Most Likely Topics of POs (Frequency in Portfolio)")
  #+ scale_y_continuous(labels = scales::percent)
  + theme_minimal()
  + theme(legend.position = "right",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4)) 
)

(
    ggplot(p1, aes(x = PO.Name, y = Percentage/100, fill = Topic1))
  + geom_bar(stat = "identity", width = 0.8)
  + ylab("Percentage")
  + xlab("PO")
  + ggtitle("Most Likely Topics of POs (Percentage of Portfolio)")
  + scale_y_continuous(labels = scales::percent)
  + theme_minimal()
  + theme(legend.position = "right",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4)) 
)
```

## Distributions of Topics

Here we look at the distributions of the percentages of each topic in each grant, and the topic distributions of each PO's portfolio.  We use standard (Tukey) boxplots. In the boxplots, the black lines are the medians and the solid black dots are the means.

```{r, fig.height = 4.1}

p1 = (
  p %>% select(PO.Name, n2)
    %>% melt(measure.vars = n2, variable.name = "Topic", value.name = "Fraction")
    %>% arrange(PO.Name)
)

g = (
    ggplot(p1, aes(x = Topic, y = Fraction, fill = Topic))
  + geom_boxplot(width = 0.8, outlier.shape = 1)
  + stat_summary(fun.y = "mean", geom = "point", size = 0.9)
  + ylab("Percentage")
  + xlab("Topic")
  + ggtitle("Distribution of Topic Percentages")
  + scale_y_continuous(labels = scales::percent)
  + theme_minimal()
  + theme(legend.position = "none",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4)) 
)

print(g)

g1 = ggplot_build(g)
colors = unique(g1$data[[1]]["fill"])
colors$Topic = sort(unique(p1$Topic))

(
    ggplot(p1, aes(x = PO.Name, y = Fraction, fill = Topic))
  + geom_boxplot(width = 0.8, outlier.shape = 1)
  + stat_summary(fun.y = "mean", geom = "point", position = position_dodge(width=0.8), size = 0.9)
  + ylab("Percentage")
  + xlab("PO")
  + ggtitle("Distribution of Topic Percentages by PO")
  + scale_y_continuous(labels = scales::percent)
  + theme_minimal()
  + theme(legend.position = "right",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle = 0, vjust = 0.4)) 
)
```


```{r, fig.height = 4.1}
for(topic in sort(unique(p1$Topic))){
  g = (
      ggplot(filter(p1, Topic == topic), aes(x = PO.Name, y = Fraction))
    + geom_boxplot(width = 0.8, fill = colors[colors$Topic == topic, "fill"], outlier.shape = 1)
    + stat_summary(fun.y = "mean", geom = "point", size = 0.9)
    + ylab("Percentage")
    + xlab("PO")
    + scale_y_continuous(limits = c(0,1), labels = scales::percent)
    + ggtitle(paste("Distribution of Topic", topic, "by PO"))
    + theme_minimal()
    + theme(legend.position = "right",
                plot.title = element_text(hjust = 0.5),
                plot.subtitle = element_text(hjust = 0.5),
                #axis.text.x = element_text(color = s$Color),
                panel.grid.major.x = element_blank())
  )
  
  print(g)
  cat("\n\n")
}
```

## Output Application Topics

```{r}
p2 = (
  p %>% mutate(
               T1 = round(100*T1, 2),
               T2 = round(100*T2, 2),
               T3 = round(100*T3, 2),
               T4 = round(100*T4, 2),
               T5 = round(100*T5, 2),
               T6 = round(100*T6, 2),
               T7 = round(100*T7, 2))
   # TODO: Include Title in file
   # %>% mutate(Title = paste0('=HYPERLINK(', 
   #                           '"https://apps.era.nih.gov/qvr/web/dd_abstract.cfm?ApplId=', 
   #                           AID, 
   #                           '&sourceCode=CURRENT&rcdc=Y"', 
   #                           ', "', 
   #                           Title, '")'))
)

write_csv(p2, "awarded-grants-NINR-2019-topics.csv")
```

